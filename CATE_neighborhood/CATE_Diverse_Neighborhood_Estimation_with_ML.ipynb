{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4dd82a",
   "metadata": {},
   "source": [
    "# Estimation of CATE conditional on Diversity of Neighborhood \n",
    "\n",
    "### (measured as proportion African American)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e719ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0c6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649e76b",
   "metadata": {},
   "source": [
    "## Load and Format the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43cb1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(\"../data/clean_data/merged_with_hosts.csv\")\n",
    "main_data_cleaned = main_data.dropna(subset=[\"yes\", \"host_race_black\", \"host_gender_M\", \"multiple_listings\", \"shared_property\", \"ten_reviews\", \"log_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db31cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_response</th>\n",
       "      <th>response_date</th>\n",
       "      <th>number_of_messages</th>\n",
       "      <th>automated_coding</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>property_type</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>number_guests</th>\n",
       "      <th>...</th>\n",
       "      <th>baltimore</th>\n",
       "      <th>dallas</th>\n",
       "      <th>los_angeles</th>\n",
       "      <th>sl</th>\n",
       "      <th>dc</th>\n",
       "      <th>total_guests</th>\n",
       "      <th>raw_black</th>\n",
       "      <th>prop_black</th>\n",
       "      <th>any_black</th>\n",
       "      <th>past_guest_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-19 08:26:17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0815</td>\n",
       "      <td>-118.2700</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>House</td>\n",
       "      <td>Flexible</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-14 14:13:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>38.9107</td>\n",
       "      <td>-77.0198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-20 16:24:08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0047</td>\n",
       "      <td>-118.4810</td>\n",
       "      <td>Pull-out Sofa</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Strict</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2015-07-20 06:47:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0917</td>\n",
       "      <td>-118.2820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House</td>\n",
       "      <td>Strict</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-18 18:07:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0809</td>\n",
       "      <td>-118.3670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Strict</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>matched (3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_response        response_date  number_of_messages  automated_coding  \\\n",
       "0              1  2015-07-19 08:26:17                 2.0                 1   \n",
       "1              0  2015-07-14 14:13:39                 NaN                 1   \n",
       "2              2  2015-07-20 16:24:08                 2.0                 0   \n",
       "3             10  2015-07-20 06:47:38                 NaN                 0   \n",
       "5              4  2015-07-18 18:07:19                 NaN                 0   \n",
       "\n",
       "   latitude  longitude       bed_type property_type cancellation_policy  \\\n",
       "0   34.0815  -118.2700       Real Bed         House            Flexible   \n",
       "1   38.9107   -77.0198            NaN         House            Moderate   \n",
       "2   34.0047  -118.4810  Pull-out Sofa     Apartment              Strict   \n",
       "3   34.0917  -118.2820            NaN         House              Strict   \n",
       "5   34.0809  -118.3670            NaN     Apartment              Strict   \n",
       "\n",
       "   number_guests  ...  baltimore  dallas  los_angeles  sl  dc total_guests  \\\n",
       "0            3.0  ...          0       0            1   0   0         11.0   \n",
       "1            2.0  ...          0       0            0   0   1        167.0   \n",
       "2            1.0  ...          0       0            1   0   0         19.0   \n",
       "3            8.0  ...          0       0            1   0   0         41.0   \n",
       "5            3.0  ...          0       0            1   0   0        263.0   \n",
       "\n",
       "  raw_black prop_black  any_black  past_guest_merge  \n",
       "0       0.0   0.000000        0.0       matched (3)  \n",
       "1       0.0   0.000000        0.0       matched (3)  \n",
       "2       0.0   0.000000        0.0       matched (3)  \n",
       "3       0.0   0.000000        0.0       matched (3)  \n",
       "5       1.0   0.003802        1.0       matched (3)  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3677d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confounders = main_data_cleaned[[\"host_race_black\", \"host_gender_M\", \"multiple_listings\", \"shared_property\", \"ten_reviews\", \"log_price\"]]\n",
    "outcome = main_data_cleaned[\"yes\"]\n",
    "treatment = main_data_cleaned[\"guest_black\"]\n",
    "condition = main_data_cleaned[\"black_proportion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195f3de",
   "metadata": {},
   "source": [
    "## Specify Nuisance Function Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bddbea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CE of fit model 0.680695717079893\n",
      "Test CE of no-covariate model 0.6917462955382059\n"
     ]
    }
   ],
   "source": [
    "# specify a model for the conditional expected outcome\n",
    "\n",
    "# make a function that returns a sklearn model for later use in k-folding\n",
    "def make_Q_model():\n",
    "    \"\"\"Create outcome model for conditional expected outcome\"\"\"\n",
    "    return RandomForestClassifier(n_estimators=100, max_depth=5, random_state=RANDOM_SEED)\n",
    "Q_model = make_Q_model()\n",
    "\n",
    "# Sanity check that chosen model actually improves test error\n",
    "# A real analysis should give substantial attention to model selection and validation \n",
    "\n",
    "X_w_treatment = confounders.copy()\n",
    "X_w_treatment[\"treatment\"] = treatment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_w_treatment, outcome, test_size=0.2)\n",
    "Q_model.fit(X_train, y_train)\n",
    "y_pred = Q_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_ce=log_loss(y_test, y_pred)\n",
    "print(f\"Test CE of fit model {test_ce}\") \n",
    "baseline_ce=log_loss(y_test, y_train.mean()*np.ones_like(y_test))\n",
    "print(f\"Test CE of no-covariate model {baseline_ce}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6d075",
   "metadata": {},
   "source": [
    "Because it is a randomized experiment. Treatment is randomly assigned and not confounded by X. Therefore, we can estimate the propensity score as g(x) = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab82d0",
   "metadata": {},
   "source": [
    "## Use cross fitting to get get predicted outcomes and propensity scores for each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee7cfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to implement the cross fitting\n",
    "\n",
    "def outcome_k_fold_fit_and_predict(make_model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
    "    \"\"\"\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    y: array of outcomes\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
    "\n",
    "    \"\"\"\n",
    "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
    "    if output_type == 'binary':\n",
    "      kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    elif output_type == 'continuous':\n",
    "      kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_w_treatment = X.copy()\n",
    "    X_w_treatment[\"A\"] = A\n",
    "\n",
    "    # for predicting effect under treatment / control status for each data point \n",
    "    X0 = X_w_treatment.copy()\n",
    "    X0[\"A\"] = 0\n",
    "    X1 = X_w_treatment.copy()\n",
    "    X1[\"A\"] = 1\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
    "      X_train = X_w_treatment.iloc[train_index]\n",
    "      if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y, index=X.index)\n",
    "      y_train = y.iloc[train_index]\n",
    "      q = make_model()\n",
    "      q.fit(X_train, y_train)\n",
    "\n",
    "      if output_type =='binary':\n",
    "        predictions0[test_index] = q.predict_proba(X0.iloc[test_index])[:, 1]\n",
    "        predictions1[test_index] = q.predict_proba(X1.iloc[test_index])[:, 1]\n",
    "      elif output_type == 'continuous':\n",
    "        predictions0[test_index] = q.predict(X0.iloc[test_index])\n",
    "        predictions1[test_index] = q.predict(X1.iloc[test_index])\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239de7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is a randomized experiment. Treatment is randomly assigned and not confounded by X. Therefore, we can estimate the propensity score as g(x) = 0.5\n",
    "g = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb992e",
   "metadata": {},
   "source": [
    "## Estimate CATEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df94fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cate_aiptw(Q0, Q1, g, A, Y):\n",
    "    \"\"\"\n",
    "    AIPTW estimator for CATE (same as ATE but applied to subgroups)\n",
    "    \"\"\"\n",
    "    tau_hat = (Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g)).mean()\n",
    "    scores = Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g) - tau_hat\n",
    "    n = Y.shape[0]\n",
    "    std_hat = np.std(scores) / np.sqrt(n)\n",
    "    return tau_hat, std_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5484a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cate_by_continuous_condition(main_data_cleaned, confounders, outcome, treatment, condition, \n",
    "                                        condition_name=\"black_proportion\", method=\"quantiles\", n_groups=3):\n",
    "    \"\"\"\n",
    "    Estimate CATE conditioned on a continuous variable (neighborhood diversity)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    method : str\n",
    "        - \"quantiles\": Split into quantile-based groups\n",
    "        - \"threshold\": Split based on specific thresholds\n",
    "        - \"bins\": Split into equal-width bins\n",
    "    n_groups : int\n",
    "        Number of groups to create (for quantiles/bins methods)\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"=== CATE Estimation by {condition_name} ===\\n\")\n",
    "    print(f\"Continuous variable summary:\")\n",
    "    print(f\"Mean: {condition.mean():.4f}\")\n",
    "    print(f\"Std: {condition.std():.4f}\")\n",
    "    print(f\"Min: {condition.min():.4f}, Max: {condition.max():.4f}\")\n",
    "    print(f\"Quantiles: {condition.quantile([0.25, 0.5, 0.75]).values}\\n\")\n",
    "    \n",
    "    # Create groups based on the continuous condition\n",
    "    if method == \"quantiles\":\n",
    "        # Split into quantile-based groups\n",
    "        condition_groups = pd.qcut(condition, q=n_groups, labels=False, duplicates='drop')\n",
    "        group_labels = {}\n",
    "        for i in range(n_groups):\n",
    "            mask = condition_groups == i\n",
    "            if mask.sum() > 0:\n",
    "                min_val = condition[mask].min()\n",
    "                max_val = condition[mask].max()\n",
    "                group_labels[i] = f\"Q{i+1}: [{min_val:.3f}, {max_val:.3f}]\"\n",
    "                \n",
    "    elif method == \"threshold\":\n",
    "        # Define meaningful thresholds for black proportion\n",
    "        # Low: < 0.1, Medium: 0.1-0.3, High: > 0.3\n",
    "        thresholds = [0.1, 0.3]\n",
    "        condition_groups = pd.cut(condition, bins=[-np.inf] + thresholds + [np.inf], \n",
    "                                labels=False, include_lowest=True)\n",
    "        group_labels = {\n",
    "            0: f\"Low Diversity: < {thresholds[0]}\",\n",
    "            1: f\"Medium Diversity: {thresholds[0]}-{thresholds[1]}\",\n",
    "            2: f\"High Diversity: > {thresholds[1]}\"\n",
    "        }\n",
    "        \n",
    "    elif method == \"bins\":\n",
    "        # Equal-width bins\n",
    "        condition_groups = pd.cut(condition, bins=n_groups, labels=False, include_lowest=True)\n",
    "        group_labels = {}\n",
    "        for i in range(n_groups):\n",
    "            mask = condition_groups == i\n",
    "            if mask.sum() > 0:\n",
    "                min_val = condition[mask].min()\n",
    "                max_val = condition[mask].max()\n",
    "                group_labels[i] = f\"Bin {i+1}: [{min_val:.3f}, {max_val:.3f}]\"\n",
    "\n",
    "                # Estimate CATE for each group\n",
    "    unique_groups = np.unique(condition_groups[~pd.isna(condition_groups)])\n",
    "    \n",
    "    for group in unique_groups:\n",
    "        group_label = group_labels.get(group, f'Group {group}')\n",
    "        print(f\"--- {group_label} ---\")\n",
    "        \n",
    "        # Filter data for this group\n",
    "        group_mask = condition_groups == group\n",
    "        group_confounders = confounders[group_mask].copy()\n",
    "        group_outcome = outcome[group_mask].copy()\n",
    "        group_treatment = treatment[group_mask].copy()\n",
    "        group_condition_values = condition[group_mask].copy()\n",
    "        \n",
    "        # Reset indices to avoid issues\n",
    "        group_confounders = group_confounders.reset_index(drop=True)\n",
    "        group_outcome = group_outcome.reset_index(drop=True)\n",
    "        group_treatment = group_treatment.reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Sample size: {len(group_outcome)}\")\n",
    "        print(f\"Treatment rate: {group_treatment.mean():.3f}\")\n",
    "        print(f\"Outcome rate: {group_outcome.mean():.3f}\")\n",
    "        print(f\"Mean {condition_name}: {group_condition_values.mean():.3f}\")\n",
    "        print(f\"{condition_name} range: [{group_condition_values.min():.3f}, {group_condition_values.max():.3f}]\")\n",
    "        \n",
    "        # Check if we have enough data\n",
    "        if len(group_outcome) < 50:\n",
    "            print(f\"Warning: Small sample size for {group_label}\")\n",
    "        \n",
    "        # Check treatment variation\n",
    "        if group_treatment.var() == 0:\n",
    "            print(f\"No treatment variation for {group_label}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Step 1: Estimate Q (outcome model) using cross-fitting\n",
    "            print(\"Estimating outcome model (Q)...\")\n",
    "            Q0, Q1 = outcome_k_fold_fit_and_predict(\n",
    "                make_Q_model, \n",
    "                X=group_confounders, \n",
    "                y=group_outcome, \n",
    "                A=group_treatment,\n",
    "                n_splits=10,\n",
    "                output_type='binary'\n",
    "            )\n",
    "            \n",
    "            # Step 2: Define g (propensity score)\n",
    "            # Since this is a randomized experiment, g = 0.5\n",
    "            g = 0.5  \n",
    "            print(f\"Using propensity score g = {g} (randomized experiment)\")\n",
    "            \n",
    "            # Alternative: Estimate propensity score if needed\n",
    "            # g_estimated = group_treatment.mean()  # Empirical treatment probability\n",
    "            \n",
    "            # Step 3: Estimate CATE using AIPTW\n",
    "            print(\"Estimating CATE...\")\n",
    "            tau_hat, std_hat = cate_aiptw(Q0, Q1, g, group_treatment, group_outcome)\n",
    "            \n",
    "            # Calculate confidence interval\n",
    "            ci_lower = tau_hat - 1.96 * std_hat\n",
    "            ci_upper = tau_hat + 1.96 * std_hat\n",
    "            \n",
    "            # Store results\n",
    "            results[group] = {\n",
    "                'group_label': group_label,\n",
    "                'n': len(group_outcome),\n",
    "                'treatment_rate': group_treatment.mean(),\n",
    "                'outcome_rate': group_outcome.mean(),\n",
    "                'mean_condition': group_condition_values.mean(),\n",
    "                'condition_range': (group_condition_values.min(), group_condition_values.max()),\n",
    "                'cate_estimate': tau_hat,\n",
    "                'std_error': std_hat,\n",
    "                'ci_lower': ci_lower,\n",
    "                'ci_upper': ci_upper\n",
    "            }\n",
    "            \n",
    "            print(f\"CATE Estimate: {tau_hat:.4f}\")\n",
    "            print(f\"Standard Error: {std_hat:.4f}\")\n",
    "            print(f\"95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "            \n",
    "            # Interpretation\n",
    "            if ci_lower > 0:\n",
    "                print(\"Significant positive effect of black-sounding names\")\n",
    "            elif ci_upper < 0:\n",
    "                print(\"Significant negative effect of black-sounding names\")\n",
    "            else:\n",
    "                print(\"No significant effect\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error estimating CATE for {group_label}: {str(e)}\")\n",
    "            \n",
    "        print(\"\\n\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e37ec2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATE Estimation by black_proportion ===\n",
      "\n",
      "Continuous variable summary:\n",
      "Mean: 0.1412\n",
      "Std: 0.2042\n",
      "Min: 0.0000, Max: 0.9835\n",
      "Quantiles: [0.0297899  0.04958272 0.14394372]\n",
      "\n",
      "--- Q1: [0.000, 0.034] ---\n",
      "Sample size: 2064\n",
      "Treatment rate: 0.492\n",
      "Outcome rate: 0.459\n",
      "Mean black_proportion: 0.022\n",
      "black_proportion range: [0.000, 0.034]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.0976\n",
      "Standard Error: 0.0215\n",
      "95% CI: [-0.1397, -0.0555]\n",
      "Significant negative effect of black-sounding names\n",
      "\n",
      "\n",
      "--- Q2: [0.034, 0.094] ---\n",
      "Sample size: 2061\n",
      "Treatment rate: 0.498\n",
      "Outcome rate: 0.443\n",
      "Mean black_proportion: 0.055\n",
      "black_proportion range: [0.034, 0.094]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.0694\n",
      "Standard Error: 0.0216\n",
      "95% CI: [-0.1118, -0.0270]\n",
      "Significant negative effect of black-sounding names\n",
      "\n",
      "\n",
      "--- Q3: [0.095, 0.984] ---\n",
      "Sample size: 2036\n",
      "Treatment rate: 0.500\n",
      "Outcome rate: 0.456\n",
      "Mean black_proportion: 0.350\n",
      "black_proportion range: [0.095, 0.984]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.0987\n",
      "Standard Error: 0.0215\n",
      "95% CI: [-0.1409, -0.0565]\n",
      "Significant negative effect of black-sounding names\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{np.float64(0.0): {'group_label': 'Q1: [0.000, 0.034]',\n",
       "  'n': 2064,\n",
       "  'treatment_rate': np.float64(0.49176356589147285),\n",
       "  'outcome_rate': np.float64(0.45930232558139533),\n",
       "  'mean_condition': np.float64(0.021865520484275498),\n",
       "  'condition_range': (np.float64(0.0), np.float64(0.0340476667334267)),\n",
       "  'cate_estimate': np.float64(-0.09760216042001296),\n",
       "  'std_error': np.float64(0.021500742208702586),\n",
       "  'ci_lower': np.float64(-0.13974361514907002),\n",
       "  'ci_upper': np.float64(-0.055460705690955896)},\n",
       " np.float64(1.0): {'group_label': 'Q2: [0.034, 0.094]',\n",
       "  'n': 2061,\n",
       "  'treatment_rate': np.float64(0.4978165938864629),\n",
       "  'outcome_rate': np.float64(0.44347404172731686),\n",
       "  'mean_condition': np.float64(0.05484460225331116),\n",
       "  'condition_range': (np.float64(0.0340860673199829),\n",
       "   np.float64(0.0944857496902106)),\n",
       "  'cate_estimate': np.float64(-0.06939628968758131),\n",
       "  'std_error': np.float64(0.02162625746849639),\n",
       "  'ci_lower': np.float64(-0.11178375432583423),\n",
       "  'ci_upper': np.float64(-0.02700882504932839)},\n",
       " np.float64(2.0): {'group_label': 'Q3: [0.095, 0.984]',\n",
       "  'n': 2036,\n",
       "  'treatment_rate': np.float64(0.50049115913556),\n",
       "  'outcome_rate': np.float64(0.45579567779960706),\n",
       "  'mean_condition': np.float64(0.34950171228227445),\n",
       "  'condition_range': (np.float64(0.0945638432364096),\n",
       "   np.float64(0.9835151515151516)),\n",
       "  'cate_estimate': np.float64(-0.09871658119270887),\n",
       "  'std_error': np.float64(0.02153608933787941),\n",
       "  'ci_lower': np.float64(-0.14092731629495253),\n",
       "  'ci_upper': np.float64(-0.05650584609046523)}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_quantile = estimate_cate_by_continuous_condition(main_data_cleaned, confounders, outcome, treatment, \n",
    "                                                condition, condition_name=\"black_proportion\", \n",
    "                                                method=\"quantiles\", n_groups=3)\n",
    "results_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd379f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATE Estimation by black_proportion ===\n",
      "\n",
      "Continuous variable summary:\n",
      "Mean: 0.1412\n",
      "Std: 0.2042\n",
      "Min: 0.0000, Max: 0.9835\n",
      "Quantiles: [0.0297899  0.04958272 0.14394372]\n",
      "\n",
      "--- Low Diversity: < 0.1 ---\n",
      "Sample size: 4195\n",
      "Treatment rate: 0.495\n",
      "Outcome rate: 0.451\n",
      "Mean black_proportion: 0.039\n",
      "black_proportion range: [0.000, 0.100]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.0831\n",
      "Standard Error: 0.0151\n",
      "95% CI: [-0.1127, -0.0535]\n",
      "Significant negative effect of black-sounding names\n",
      "\n",
      "\n",
      "--- Medium Diversity: 0.1-0.3 ---\n",
      "Sample size: 1062\n",
      "Treatment rate: 0.502\n",
      "Outcome rate: 0.444\n",
      "Mean black_proportion: 0.176\n",
      "black_proportion range: [0.100, 0.298]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.1290\n",
      "Standard Error: 0.0299\n",
      "95% CI: [-0.1876, -0.0703]\n",
      "Significant negative effect of black-sounding names\n",
      "\n",
      "\n",
      "--- High Diversity: > 0.3 ---\n",
      "Sample size: 904\n",
      "Treatment rate: 0.497\n",
      "Outcome rate: 0.470\n",
      "Mean black_proportion: 0.573\n",
      "black_proportion range: [0.300, 0.984]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.0610\n",
      "Standard Error: 0.0324\n",
      "95% CI: [-0.1245, 0.0025]\n",
      "No significant effect\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{np.float64(0.0): {'group_label': 'Low Diversity: < 0.1',\n",
       "  'n': 4195,\n",
       "  'treatment_rate': np.float64(0.49535160905840286),\n",
       "  'outcome_rate': np.float64(0.4512514898688915),\n",
       "  'mean_condition': np.float64(0.039307727972410424),\n",
       "  'condition_range': (np.float64(0.0), np.float64(0.0996316758747698)),\n",
       "  'cate_estimate': np.float64(-0.08309351340362497),\n",
       "  'std_error': np.float64(0.015119547973875198),\n",
       "  'ci_lower': np.float64(-0.11272782743242037),\n",
       "  'ci_upper': np.float64(-0.05345919937482958)},\n",
       " np.float64(1.0): {'group_label': 'Medium Diversity: 0.1-0.3',\n",
       "  'n': 1062,\n",
       "  'treatment_rate': np.float64(0.5018832391713748),\n",
       "  'outcome_rate': np.float64(0.4444444444444444),\n",
       "  'mean_condition': np.float64(0.17568376830386453),\n",
       "  'condition_range': (np.float64(0.1002004008016032),\n",
       "   np.float64(0.2976942282273461)),\n",
       "  'cate_estimate': np.float64(-0.12897705924612102),\n",
       "  'std_error': np.float64(0.02991524895320026),\n",
       "  'ci_lower': np.float64(-0.18761094719439353),\n",
       "  'ci_upper': np.float64(-0.0703431712978485)},\n",
       " np.float64(2.0): {'group_label': 'High Diversity: > 0.3',\n",
       "  'n': 904,\n",
       "  'treatment_rate': np.float64(0.49668141592920356),\n",
       "  'outcome_rate': np.float64(0.47013274336283184),\n",
       "  'mean_condition': np.float64(0.5733169966231902),\n",
       "  'condition_range': (np.float64(0.300077339520495),\n",
       "   np.float64(0.9835151515151516)),\n",
       "  'cate_estimate': np.float64(-0.061007177445080836),\n",
       "  'std_error': np.float64(0.03239453005473514),\n",
       "  'ci_lower': np.float64(-0.1245004563523617),\n",
       "  'ci_upper': np.float64(0.0024861014622000396)}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_threshold = estimate_cate_by_continuous_condition(main_data_cleaned, confounders, outcome, treatment, \n",
    "                                                condition, condition_name=\"black_proportion\", \n",
    "                                                method=\"threshold\", n_groups=3)\n",
    "results_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "575f5d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CATE Estimation by black_proportion ===\n",
      "\n",
      "Continuous variable summary:\n",
      "Mean: 0.1412\n",
      "Std: 0.2042\n",
      "Min: 0.0000, Max: 0.9835\n",
      "Quantiles: [0.0297899  0.04958272 0.14394372]\n",
      "\n",
      "--- Bin 1: [0.000, 0.326] ---\n",
      "Sample size: 5344\n",
      "Treatment rate: 0.497\n",
      "Outcome rate: 0.451\n",
      "Mean black_proportion: 0.071\n",
      "black_proportion range: [0.000, 0.326]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.0920\n",
      "Standard Error: 0.0134\n",
      "95% CI: [-0.1182, -0.0658]\n",
      "Significant negative effect of black-sounding names\n",
      "\n",
      "\n",
      "--- Bin 2: [0.330, 0.651] ---\n",
      "Sample size: 511\n",
      "Treatment rate: 0.499\n",
      "Outcome rate: 0.438\n",
      "Mean black_proportion: 0.468\n",
      "black_proportion range: [0.330, 0.651]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.0518\n",
      "Standard Error: 0.0425\n",
      "95% CI: [-0.1352, 0.0315]\n",
      "No significant effect\n",
      "\n",
      "\n",
      "--- Bin 3: [0.656, 0.984] ---\n",
      "Sample size: 306\n",
      "Treatment rate: 0.484\n",
      "Outcome rate: 0.516\n",
      "Mean black_proportion: 0.823\n",
      "black_proportion range: [0.656, 0.984]\n",
      "Estimating outcome model (Q)...\n",
      "Using propensity score g = 0.5 (randomized experiment)\n",
      "Estimating CATE...\n",
      "CATE Estimate: -0.0797\n",
      "Standard Error: 0.0561\n",
      "95% CI: [-0.1897, 0.0303]\n",
      "No significant effect\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{np.float64(0.0): {'group_label': 'Bin 1: [0.000, 0.326]',\n",
       "  'n': 5344,\n",
       "  'treatment_rate': np.float64(0.49719311377245506),\n",
       "  'outcome_rate': np.float64(0.4505988023952096),\n",
       "  'mean_condition': np.float64(0.07085605918464628),\n",
       "  'condition_range': (np.float64(0.0), np.float64(0.3259127337488869)),\n",
       "  'cate_estimate': np.float64(-0.09197959048605067),\n",
       "  'std_error': np.float64(0.013377955332726867),\n",
       "  'ci_lower': np.float64(-0.11820038293819533),\n",
       "  'ci_upper': np.float64(-0.06575879803390601)},\n",
       " np.float64(1.0): {'group_label': 'Bin 2: [0.330, 0.651]',\n",
       "  'n': 511,\n",
       "  'treatment_rate': np.float64(0.49902152641878667),\n",
       "  'outcome_rate': np.float64(0.4383561643835616),\n",
       "  'mean_condition': np.float64(0.4682469768223934),\n",
       "  'condition_range': (np.float64(0.3302966101694915),\n",
       "   np.float64(0.6514781665310551)),\n",
       "  'cate_estimate': np.float64(-0.05183022282798179),\n",
       "  'std_error': np.float64(0.042538011171397196),\n",
       "  'ci_lower': np.float64(-0.1352047247239203),\n",
       "  'ci_upper': np.float64(0.03154427906795672)},\n",
       " np.float64(2.0): {'group_label': 'Bin 3: [0.656, 0.984]',\n",
       "  'n': 306,\n",
       "  'treatment_rate': np.float64(0.48366013071895425),\n",
       "  'outcome_rate': np.float64(0.5163398692810458),\n",
       "  'mean_condition': np.float64(0.8229466022592712),\n",
       "  'condition_range': (np.float64(0.6562220232766338),\n",
       "   np.float64(0.9835151515151516)),\n",
       "  'cate_estimate': np.float64(-0.07969010096018254),\n",
       "  'std_error': np.float64(0.05614095559177943),\n",
       "  'ci_lower': np.float64(-0.18972637392007025),\n",
       "  'ci_upper': np.float64(0.030346171999705143)}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bins = estimate_cate_by_continuous_condition(main_data_cleaned, confounders, outcome, treatment, \n",
    "                                                condition, condition_name=\"black_proportion\", \n",
    "                                                method=\"bins\", n_groups=3)\n",
    "results_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac6e69",
   "metadata": {},
   "source": [
    "It is interesting to observe that the selection of grouping method affects whether the effect is seen as significant or not. With quantile-based groups, all groups see a significant effect. With threshold-based groups, only the highest proportion group doesn't see a significant effect. With equal-size bins, only the lowest proportion group sees a significant effect. This assumes three groups (low, mid, high) which can be changed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
